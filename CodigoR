pkg <- function(pkg){
  new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
  if (length(new.pkg)) 
    install.packages(new.pkg, dependencies = TRUE)
  sapply(pkg, require, character.only = TRUE)
}

packages <- c("tidyverse","raster","sf","ggspatial","cluster","factoextra",
              "NbClust","tidyr","forecast","semTools","corrplot",
              "corrr","haven","psych","dplyr","lavaan","readr","cvms","tm",
              "NLP","SnowballC","RColorBrewer","wordcloud","wordcloud2",
              "RefManageR","bibliometrix","GGally","quanteda","ggplot2",
              "ggpubr","Factoshiny","syuzhet","RColorBrewer","tokenizers",
              "stringr","sentimentr","stringi","stopwords","twitteR",
              "mscstexta4r","plyr","psych","corrr","latticeExtra",
              "semPlot","lavaan","readr","lme4","sjPlot","gvlma","Rcmdr",
              "tidymodels","caret","lmtest","gapminder","png","rtweet","knitr")

pkg(packages)

#C√≥mo abrir un archivo desde el equipo?
#Escribo el comando read_csv('dentro la ruta de mi archivo')
archivo <- read_csv('/home/alrier/Documentos/movies datasets/WideReleasesCount.csv')
cars<-read_csv('/home/alrier/Documentos/Big_data/USA_cars_datasets.csv')
data("gapminder")
archivo <- WideReleasesCount

#VECTORES----------------------------------------
a <- c(2,4,1,8)
b <- c(2,2,2,2)

#Puedo poseer diferentes tipos de vectores
vector_double <-c(1, 2.5, 4.5, 25)
# Con el sufijo L, conseguimos un integer en lugar de un double
vector_integer <-c(1L, 6L, 10L)
# Usamos TRUE y FALSE (o T y F) para crear vectores l√≥gicos
vector_logical <-c(TRUE, FALSE, T, F)  
vector_character <-c("Hola", "Mundo!", "4343434", "ssfkjdfdkjflkshfklj")

#Length nos ayuda a conocer la longitud de cualquier vector. 
length(vector_logical)
length(vector_double)
length(archivo)

#Operaciones Vectorizadas-------------------------------------------------------------
c<-a+b
c<-a/b
#reciclaje de elementos en los vectores. 

'''supongamos que tenemos dos vectores a y b'''
a<-c(1,2)
b<-c(1,2,3,4)
'''pero deseamos crear una operaic√≥n con estos dos vectores sumandolos'''
d<-a+b
'''veremos que el resultado de ellos es la suma de las dos primeras partes del vector
y R recicla la otra parte del vector para no perder datos'''


#Matrices--------------------------------------------------------------------
#Para crear matrices utilizaremos la funci√≥n matrix() , la sintaxis es la siguiente
str(matrix)
function (data = NA, nrow = 1, ncol = 1, byrow = FALSE, dimnames = NULL)
  '''A continuaci√≥n mostramos la descripci√≥n de los argumentos:
data = es el vector que contiene los elementos que formaran parte de la matriz.
nrow = es el n√∫mero de filas.
ncol = es el n√∫mero de columnas.
byrow = es un valor l√≥gico. Si es TRUE el vector que pasamos ser√° ordenado por filas.
dimnames = nombres asignado a filas y columnas.'''
#Seguidamente se muestra un ejemplo de creaci√≥n de una matriz:
matriz <- matrix(1:12, nrow = 4)
matriz
#ejemplo de una matriz usando los argumentos previamente aprendidos. 
automoviles <- matrix(
  1:12,
  nrow = 4, #numero de filas
  byrow = TRUE, #ordenado por filas.
  dimnames = list( #nombre de las filas y las columnas
    c("Blanco", "Rojo", "Negro", "Gris"),
    c("Toyota", "Audi", "Nissan")
  )
)

automoviles <- matrix(
  1:12,
  nrow = 4, 
  byrow = TRUE,
  dimnames = list(
    c("Blanco", "Rojo", "Negro", "Gris"),
    c("Toyota", "Audi", "Nissan")
  )
)

#cbind(), rbind() agregar filas y columnas organizandolas de forma manual. 

v1 <- c(1, 2, 3)
v2 <- c(4, 5, 6)
m1 <- cbind(v1, v2)
m1

nombres <- c("Pedro","Maria","Juan")
apellidos <- c("Gonzales", "Gomez", "vuelolindo")
nomrbres_y_apellidos <- rbind(nombres,apellidos)
nomrbres_y_apellidos2 <- cbind(nombres,apellidos)

v1 <- c(1, 2, 3)
v2 <- c(4, 5, 6)
m1 <- rbind(v1, v2)
m1

#Listas-------------------------------------------------------------------
lista <- list(1:3, "Ruben", pi, list(c(-1, -2), -5))
lista

#nombrar listas 
'''se puede nombrar las listas como se desee una vez se han creado'''
data_list <- list(c("enero","Febrero","Marzo"), #aqu√≠ creo las listas
                  matrix(c(1,2,3,4,-1,9), nrow = 2),#asigno categirias a lo que hay dentro
                  list("Rojo",12.3))


#con el comando names yo puedo nombrar los objetos dentro de una lista
#el comando es names(introduzco el nombre del objeto a nombrar)
names(data_list) <- c("listaA", "listaB", "listaC") #aqu√≠ nombro las listas
data_list #aqu√≠ imprimo el contenido de las listas

listab.1 <-data_list$listaB #aqu√≠ extraigo la lista B en un objeto 
#nuevo que se llamar√° listab.1

archivo.1 <- archivo$`SONY PICTURES`
archivo2 <- archivo$`PARAMOUNT PICTURES`

tabla<-cbind(archivo.1,archivo2)

print(data_list[3]) #as√≠ accedo a las listas e imprimo su contenido. 

data_list[4] <- "New element" #agrego un nuevo elemento a la lista (al final)
print(data_list[4]) 

data_list[4] <- NULL #remover el elemento 
print(data_list[4]) #se elimina el √∫ltimo elemento agregado.

#modifico el 3er elemento de la lista
#*********************

print(data_list[3])

#Ahora como mezclar listas. 
num_list <- list(1,2,3,4,5) #creo una lista 1
day_list <- list("Mon","Tue","Wed", "Thurs", "Fri") #creo la lista 2
merge_list <- c(num_list, day_list) #las mezclo
merge_list #llamo al producto

'''las listas se mezclan quedando una lista m√°s grande con todo el c√≥digo y todo
el contenido de las que antes eran dos listas separadas. '''

#data.frame()-------------------------------------------------------------
#IMPORTANTE
nombre <- c("Juan", "Ruben", "Daniel", 0) 
apellido <- c("Sanchez", "Garcia", "Sancho", "Alfara") 
fecha_nacimiento <- c("1976-06-14", "1974-05-07", "1958-12-25", "1983-09-19")
sexo <- c("HOMBRE", "MUJER", "HOMBRE", "HOMBRE")
nro_hijos <- c(1, 2, 3, 4) 

censo <- data.frame(nombre, apellido, fecha_nacimiento, sexo, nro_hijos) 
#ojo al error... arguments imply differing number of rows: 3,4. 



'''se debe tener en cuenta que el dataframe est√° conformoado por un n√∫mero 
de vectores, los cuales para poder realizar operaciones aritm√©ticas de adeci√≥n
mezcla u otra operaci√≥n deben poseer un n√∫mero igual de datos'''

int_vec <- c(1,2,3) #creo 3 vectores un con enteros, otro con caracteres 
char_vec <- c("a", "bsvjkzlkvdnl<zkjvdnl", "zdvzxvzxbc")# y uno con boleanos. 
bool_vec <- c(TRUE, TRUE, FALSE)

data_frame <- data.frame(int_vec, char_vec,bool_vec)#crear√© mi dataframe

#Nuevamente
employee_data <- data.frame(
  employee_id = c (1:5), #defino un elemento compueso por un conteo de 1 a 5
  employee_name = c("Jaime","Henrry","julia","Jimmy","Oliver"), #5 nombres
  sal = c(642.3,535.2,681.0,739.0,925.26), #5 "salarios" hipoteticos
  join_date = as.Date(c("2013-02-04", "2017-06-21", "2012-11-14", "2018-05-19","2016-03-25"))
)

#que tipo de variables componen mi Dataframe?
str(employee_data)

#extraigo informaci√≥n del Fataframe 
a<- employee_data$sal
b<-employee_data$employee_name
#aplico lo aprendido y mezclo la informaci√≥n para crear una nueva tabla con las
#variables a y b que extraje previamente de mi dataframe. 
mix <- cbind(a, b)
#ahora creo una variabe nueva
c<- c(1,2,3,4,5)
#la introduzco en mi nueva tabla
mix2 <- cbind(mix, c)
mix2
#la convierto en dataframe
pan <- as.data.frame(mix2)
mix2df#cu√°l fue la diferencia?

#ahora, de un dataframe, yo puedo extraer varios elementos a la vez
output <- data.frame(employee_data$employee_name, employee_data$employee_id)
print(output)
#O extraer 2 rows completas
output <- employee_data[1:2,0]#deber√≠a ser este el comando?
#error, puesto que extrae la columna 0
output <- employee_data[1:2,]
output <- employee_data[1:5,]
output <- employee_data[,2]
print(output)

#ahora, extraigo 1 y 2 row con la columa 3 y 4.
result <- employee_data[c(1,2),c(3,4)]
result

#agregando columnas
employee_data$deptartamento <- c("tecolog√≠a","Finanzas","Operaciones",
                                 "recursos humanos","Administraci√≥n")
out <- employee_data
print(out)


#creo un nuevo dataframe
employee_new_data <- data.frame(
  employee_id = c (1:5),
  employee_name = c("Amanda", "Mauricio", "Andres", "Pedro", "Manuel"),
  sal = c(523.0,721.3,622.8,721.3,622.8),
  deptartamento = c("tecolog√≠a","Finanzas","Operaciones",
                    "recursos humanos","Administraci√≥n"),
  join_date = as.Date(c("2015-06-22","2016-04-30","2011-03-17","2016-04-30",
                        "2011-03-17")), stringsAsFactors = FALSE)

print(employee_new_data)

#uniendo √°mbos dataframe
employee_out_data <- rbind(employee_data,employee_new_data)
employee_out_data 

#B√°ses de trabajo con dyplyer-------------------------------------
#cargar√© los datos de la libreria

#rectifico que hayan quedado bien cargados
data("gapminder")
head(gapminder)

head(archivo)
view(archivoo)
# filtrar datos por pais sin %>%  == >=  
f<-filter(gapminder, country == 'Mexico')
#extraer todos los registros de todos los registros de sony para el a√±o2018
filtro1<-filter(gapminder, country == '')
# filtrar datos por pais
# para hacer %>% en RStudio (cntrl + shift + M)
f<- gapminder %>%
  filter(country == 'Mexico')

continentes<-gapmider %>% 
  filter(continent == 'Asia')
# filtrar datos por a√±o
a√±o<- gapminder %>% 
  filter(year == '1952')
# filtrar paises con esperanza de vida mayor o igual a 40 y el a√±o en 2002
gapminder %>% 
  filter(lifeExp <=40,
         year == 2002)
# hacer resumenes de datos---------------------------------------------

# cantidad de paises en Asia para el a√±o 2007 
paises<-gapminder %>% 
  filter(continent == 'Asia',
         year == 2007) %>%
  summarise(conteo = n())

# maxima esparanza de vida
q<-gapminder %>% 
  summarise(max(lifeExp))
# agrupando esperanza de vida promedio por a√±o
promedio<-gapminder %>% 
  group_by(year) %>% 
  summarise(mean(lifeExp))

#dyplyer m√°s a profundidad----------------------------------------------------
archivo %>%
  group_by(YEAR) %>%
  summarize(mean(UNIVERSAL))

z<-gapminder %>%
  group_by(continent, year) %>%
  summarize(sum(lifeExp))

z1<- gapminder%>%
  group_by(year) %>%
  filter(continent == 'Asia') %>%
  mutate(asiaxa√±o = m(pop))

#funci√≥n mutate
z1<- archivo %>%
  group_by(YEAR) %>%
  filter(UNIVERSAL == 10) %>%
  mutate(Pelis = mean(UNIVERSAL))


# el objeto est√° comprendido en. 
employee_new_data %>%
  filter(employee_name %in% c("Amanda")) 

#El objeto NO esta comprendido en. 
employee_new_data %>%
  filter(!employee_name %in% c("Amanda"))

#un filtro de todos los a√±os que tengan 0, despues haga un mutate en una
#columna nueva y guardelos seguncontengan o no el comando que yo le indique. 
ceros<-archivo_tible %>%
  mutate(
    contiene_0 = grepl('0', YEAR)) %>%
  select_('YEAR', 'contiene_0')


#comando across ---------------------------------------------------
'''nos ayuda a aplicar un mismo comando sobre diferentes lineas de codigo o sobre una variable especifica'''

'''si quiero sacar el minimo, maximo y media de la esperanza de vida, del producto
percapital del pais y de la vairbale llmada gdp, pordia hacerlo asi:'''

gapminder %>%
  group_by(year) %>%
  summarise(
    
    # Esperanza de vida
    lifeExp_min = min(lifeExp),
    lifeExp_max = max(lifeExp),
    lifeExp_mean = mean(lifeExp),
    
    # Poblacion
    pop_min = min(pop),
    pop_max = max(pop),
    pop_mean = mean(pop),
    
    # GDP
    gpd_min = min(gdpPercap),
    gpd_max = max(gdpPercap),
    gpd_mean = mean(gdpPercap)
    
  )

'''o podria hacerlo mucho mas facil, asi:'''

gapminder %>%
  group_by(year) %>%
  summarise(
    across(
      c(lifeExp,pop, gdpPercap), 
      list(min, max, mean)
    )
  )



#TRABAJANDO CON TWITTER-----------------------------------------------

'''primero que nada hay que acceder a la APLI de twitter para tener acceso a 
toda la informaci√≥n de la plataforma, una vez ah√≠ debemos entrar a la aplicaci√≥n
de las apps que tenemos desarrolladas, debemos buscar los keys y credenciales
de las apps que trabajaremos.'''

setup_twitter_oauth("6gMch1lkCfn3W5PZho3X4jh8W",#api key
                    "eBosfeWmQVBLQ87WiVMaRXousYRdyOkyhLkvCUzw7ioz0EMCWY",#api secret key
                    "284827529-UENNMA2jVHCRBYwcddd6obAAZvaJ0hUVSapYYmwZ",#acces token
                    "sb1fgjDG9CSugsU5qsWJWkBOvP91FxJmcm7hKCyajrndT")#acces token secret

'''Uso el comando searchTwitter para buscar informaci√≥n dentro de twitter con 
la palabra clave que yo deseo buscar'''

a<- searchTwitter("@FicoGutierrez", n=500)
a[1:100]
C1<-searchTwitter('Claudia Lopez', since='2020-03-01', until='2022-03-02', n=200)
C2<-searchTwitter('@ClaudiaLopez', since='2020-03-01', until='2022-03-02', n=200)
C3<-userTimeline('@ClaudiaLopez', since='2020-03-01', n=200)
C3[1]
#searchTwitter('Claudia Lopez', resultType = "popular"/"recent")

petroski<-searchTwitter('Petro', n=500)

#creando un dataframe con la informaci√≥n obtenida. 

#qu√≠ extraigo los tw
fico<-twListToDF(a)
#hago elfiltro de los retweets mayores o iguales a 1000 (los mas populares)
petro <-petroski %>%
  filter(retweetCount >= 1000)
#extraigo el texto a una variable llamada te
B<-fico$text
#hago el analisis de sentimiento
sentimientos_df <- get_nrc_sentiment(B, lang="spanish")
s<-summary(sentimientos_df)

#Hago la grafica de barras
barplot(
  colSums(prop.table(sentimientos_df[, 1:10])),
  space = 0.2,
  horiz = FALSE,
  las = 1,
  cex.names = 0.7,
  col = brewer.pal(n = 10, name = "Set3"),
  main = "Mapa de fico",
  sub = "fico presidente",
  xlab="emociones", ylab = "Frecuancia")

#AHORA TRABAJANDO CON RTWEET--------------------------------------------------
#parse es el comando usado para recibid un data frame o una lista de objetos.
create_token(app="Clase_big_data",
             consumer_key = "6gMch1lkCfn3W5PZho3X4jh8W",#api key
             consumer_secret = "eBosfeWmQVBLQ87WiVMaRXousYRdyOkyhLkvCUzw7ioz0EMCWY",#api secret key
             access_token ="284827529-UENNMA2jVHCRBYwcddd6obAAZvaJ0hUVSapYYmwZ",#acces token
             access_secret ="sb1fgjDG9CSugsU5qsWJWkBOvP91FxJmcm7hKCyajrndT")#acces token secret

C4 <- get_timeline(user = "@ClaudiaLopez", n = 200, parse = TRUE, check = FALSE)
C5 <- get_timeline(user = "@ClaudiaLopez", n = 200, parse = F, check = FALSE)
#Un peque√±o an√°lisis de sentimientos------------------------------------------
te<-fico$text
texto = Corpus(VectorSource(te)) 
#texto_palabras <- get_tokens(a)
sentimientos_df <- get_nrc_sentiment(te, lang="spanish")
s<-summary(sentimientos_df)
#barplot
barplot(
  colSums(prop.table(sentimientos_df[, 1:8])),
  space = 0.2,
  horiz = FALSE,
  las = 1,
  cex.names = 0.7,
  col = brewer.pal(n = 8, name = "Set3"),
  main = "Uso de twitter para webscraping",
  sub = "An√°lisis de sentimientos",
  xlab="emociones", ylab = "Frecuancia")


#Ahora hagamos un data mining -----------------------------------------------
#elimino puntuci√≥n y caracteres especiales
discurso <- gsub("[[:cntrl:]]", " ", te)
discurso[2]
#Convertimos todo a min√∫sculas.
discurso <- tolower(discurso)
#quto las stopwords("spanish").
discurso <- removeWords(discurso, words = stopwords("spanish"))
discurso <- removeWords(discurso, words = c("hp2pdfmnfa","@iandresrm","va","https://","@",":",
                                            "‚Ä¶","t.co/","üëÅ","@christi11079874","üì¢","jajajajjaja",
                                            "‚Äú","n","cad‚Ä¶","@lafm","plat‚Ä¶",
                                            "‚Ä¶", "indra","dos","d√≠a","üá®üá¥"))
#Nos deshacemos de la puntuaci√≥n.
discurso <- removePunctuation(discurso)
#removemos los n√∫meros.
discurso <- removeNumbers(discurso)
#conformo un vector de palabras
discurso1 <- Corpus(VectorSource(discurso)) 

discurso=tm_map(discurso, removeWords, c("gustavo"))
#organizo el compendio de palabras en un objeto tipo matriz de datos
letras<- TermDocumentMatrix(discurso1)
letrasmatrix <- as.matrix(letras) 
'''hago un vector que va a sumar la repetici√≥n de palabras en la matriz y as√≠
consigo la frecuencia total de palabras que hay para cada t√©rmino, despues le digo
que las sume y las organice'''
vector <- rowSums(letrasmatrix) 
Vectorr<- sort(vector, decreasing = T)
'''ahora bien, cabe revisar la frecuencia de palabras para as√≠ poder identificar 
cuales de estas palabras son y cuales de estas palabras no me son √∫tiles por eso 
imprimo la matriz antes de que podamos sacar conclusiones del analisis'''
#ver el vector
view(Vectorr)
#Inspeccionar la matriz ordenadamente
Vectorr[1:20]
'''AHORA ES IMPORTANTISIMO: si veo que en el vector de palabras hay algun termino
que est√© molestando demasiado, la forma mas f√°cil de eliminarlo es regresar al 
corpus y quitarlo arriba con el comando removeWords y repetir los pasos hasta 
aqu√≠, pero se debe tener en cuenta que es mejor retroceder y correr todos los
comandos de limpeza nuevamente, desde el princpio, es decir, desde
aqu√≠ discurso <- gsub("[[:cntrl:]]", " ", a) pero ahora incluyendo los terminos
que se desea eliminar del comando removeWords'''
#transformo todo en un dataframe
dataletras <- data.frame(word= names(Vectorr),freq=Vectorr)  

#findFreqTerms(letras, lowfreq=3) 
#vector <- sort(rowSums(matrix),decreasing=TRUE)
barplot(dataletras[1:10,]$freq, las = 2, names.arg = dataletras[1:10,]$word, 
        col = brewer.pal(n = 8, name = "Set3"), main ="Pabalras mas frecuentes",
        ylab = "Frecuencia de palabras") 


dataletras[1:10, ] %>%
  ggplot(aes(word, freq)) +
  geom_bar(stat = "identity", color = "black", fill = "#87CEFA") +
  geom_text(aes(hjust = 1.3, label = freq))+ 
  coord_flip() + 
  labs(title = "Diez palabras m√°s frecuentes",  x = "Palabras", y = "N√∫mero de usos")


dataletras %>%
  mutate(perc = (frec/sum(frec))*100) %>%
  .[1:10, ] %>%
  ggplot(aes(palabra, perc)) +
  geom_bar(stat = "identity", color = "black", fill = "#87CEFA") +
  geom_text(aes(hjust = 1.3, label = round(perc, 2))) + 
  coord_flip() +
  labs(title = "Diez palabras m√°s frecuentes en Niebla", x = "Palabras", y = "Porcentaje de uso")
#nube de palabras sin frecuencias m√≠nimas
wordcloud(
  words = dataletras$word, freq = dataletras$freq,
  max.words = 80, 
  random.order = F, 
  colors=brewer.pal(name = "Dark2", n = 8)
)
#nube de palabras con frecuencias m√≥nimas
wordcloud(words = dataletras$word, freq = dataletras$freq, min.freq = 2,
          max.words=30, random.order=FALSE, rot.per=0.35,  
          colors=brewer.pal(7, "Dark2"), scale=c(3.5,1.25))


#wordcloud2(data=dataletras, size=0.7,
#           color='random-dark', shape = 'triangle')

'''Veamos ahora c√≥mo se asocian algunas palabras (terms) en Niebla con la 
funci√≥n findAssocs. Como podemos introducir un vector, podemos obtener las 
asociaciones de varias palabras a la vez. He elegido 
"Petro", "petro","Uribe", "uribe"

Es importante recordar que con esto no estamos pidiendo la asociacion de estas
cuatro palabras entre si, sino las asociaciones para cada una de las cuatro, que
no necesariamente deben coincidir.

Esta tambi√©n nos pide el l√≠mite inferior de correlaci√≥n (corlimit)
para mostrarnos. Valores cercanos a 1 indican que las palabras aparecen casi
siempre asociadas una con otra, valores cercanos a 0 nos indican que nunca o
casi nunca lo hacen.

El valor que decidamos depende del tipo de documento y el tipo de asociaciones
que nos interesen. para nuestros fines, lo he fijado en .25.'''
findAssocs(letras, terms = c("Petro", "petro",
                             "Uribe", "uribe"), corlimit = .25)
#CLUSTERING DE PALABRAS------------------------------------------------------
'''ahora vamos a eliminar primero todos los terminos dispersos paraque no jodan,
como se trata de una correlaci√≥n los valores que manejaremos ser√°n de 0 a 1'''
nov_new <- removeSparseTerms(letras, sparse = .95)
#llevamos el objeto a matriz
nov_new <- nov_new %>% as.matrix()
#Matriz de distancia--------------------------------------------------------
'''Necesitamos crear una matriz de distancias para empezar agrupar, lo cual 
requiere que los valores en las celdas sean estandarizados de alguna manera.

Podr√≠amos usar la funci√≥n scale, pero realiza la estandarizaci√≥n usando la media
de cada columna como referencia, mientras que nosotros necesitamos como 
referencia la media de cada rengl√≥n.

As√≠ que obtenemos una estandarizaci√≥n por renglones de manera manual.'''
nov_new <- nov_new / rowSums(nov_new)
#Hecho esto, nuestra matriz ha sido estandarizada.
'''Procedemos a obtener una matriz de distancia a partir de ella, con el m√©todo
de distancias euclidianas y la asignamos al objeto nov_dist.'''
nov_dist <- dist(nov_new, method = "euclidian")
'''Realizaremos nuestro agrupamiento jer√°rquico usando la funci√≥n hclust, de la
base de R. Este es en realidad un procedimiento muy sencillo una vez que hemos
realizado la preparaci√≥n.

Usaremos el m√©todo de Ward (ward.D), que es el m√©todo por defecto de la funci√≥n
hclust y asignaremos sus resultados al objeto nov_hclust.'''
nov_hclust <-  hclust(nov_dist, method = "ward.D")
#Graficamos los resultados usando plot para generar un dendrograma.
plot(nov_hclust, main = "Dendrograma de Niebla - hclust", sub = "", xlab = "")
'''De este modo podemos observar los grupos de palabras que existen en Niebla. 
Por ejemplo, ‚Äúaugusto‚Äù y ‚Äúeugenia‚Äù forman un grupo, ‚Äúpuede‚Äù y ‚Äúser‚Äù, forman otro
grupo (‚Äúpuede ser‚Äù es una frase com√∫n en este libro).

Adem√°s, podemos ver qu√© palabras pertenecen a grupos lejanos entre s√≠, 
por ejemplo, ‚Äúquiero‚Äù y ‚Äúverdad‚Äù.

Podemos enfatizar los grupos de palabras trazando un rect√°ngulo usando
rect.hclust y con especificando cu√°ntos grupos (k) deseamos resaltar.

Crearemos el mismo gr√°fico pidiendo diez grupos.'''

plot(nov_hclust, main = "Dendrograma de Niebla - hclust", sub = "", xlab = "")
rect.hclust(nov_hclust, k = 10, border="blue")

#Puedo exportar cualquier elemento en forma de csv al computador, la formmula es:
'''le pido al computador que write.csv (escriba un csv), entonces tendremos:
write.csv(nombre del objeto que quiero pasar,
le pido que lo copie con la funci√≥n paste) y nombro el directorio al que lo voy a pasar
despues el nombre del archivo, el tipo de separador que usar√©, la codificaci√≥n
que usar√© (generalmente UTF-8 es la del espa√±ol que tiene tildes y √±) y finalizo
quit√°ndole los nombres a las filas para que no moleste en caso de tenerlas...
asi pues el comando quedar√≠a as√≠:'''
#Write.csv(objetoA, paste(directorio, "nombre del nuevo archivo.csv, sep =";"), fileEncoding= "UTF-8", row.names=F)
